@InProceedings{Su_2020_CVPR_Instance,
author = {Su, Jheng-Wei and Chu, Hung-Kuo and Huang, Jia-Bin},
title = {Instance-Aware Image Colorization},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2020},
pages = {7968-7977}
},
@Article{Gupta_2012_SimilarImage,
  title={Image colorization using similar images},
  author={Raj Kumar Gupta and Alex Yong Sang Chia and Deepu Rajan and Ee Sin Ng and Zhiyong Huang},
  journal={Proceedings of the 20th ACM international conference on Multimedia},
  year={2012},
  url={\url{https://api.semanticscholar.org/CorpusID:5662249}},
},
@Article{Iizuka_2016_SIGGRAPH,
  author = {Satoshi Iizuka and Edgar Simo-Serra and Hiroshi Ishikawa},
  title = {{Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification}},
  journal = "ACM Transactions on Graphics",
  year = {2016},
  volume = {35},
  number = {4},
  pages = {110:1--110:11},
  Articleno = {110}
},
@Article{Sykora_2009-LazyBrush,
  author =  "Daniel S{\'y}kora and John Dingliana and Steven Collins",
  title =   "{LazyBrush}: {Flexible} Painting Tool for Hand-drawn Cartoons",
  journal = "Computer Graphics Forum",
  volume =  "28",
  number =  "2",
  pages =   "599--608",
  year =    "2009",
},
@InProceedings{jolicoeur-martineau2018_RGAN,
title={ The relativistic discriminator: a key element missing from standard {GAN}},
author={Alexia Jolicoeur-Martineau},
booktitle={International Conference on Learning Representations (ICLR)},
year={2019},
url={\url{https://openreview.net/forum?id=S1erHoR5t7}}
},
@Article{Isola_2017_CVPR_pix2pix,
  title={Image-to-Image Translation with Conditional Adversarial Networks},
  author={Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A Efros},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={5967-5976},
  url={\url{https://api.semanticscholar.org/CorpusID:6200260}}
},
@Article{KUANG_2020_Infrared_TIC-CGAN,
title = {Thermal infrared colorization via conditional generative adversarial network},
journal = {Infrared Physics and Technology},
volume = {107},
pages = {103338},
year = {2020},
issn = {1350-4495},
author = {Xiaodong Kuang and Jianfei Zhu and Xiubao Sui and Yuan Liu and Chengwei Liu and Qian Chen and Guohua Gu},
keywords = {Infrared images, Colorization, Deep learning, Convolutional neural networks},
url = {\url{https://www.sciencedirect.com/science/Article/pii/S1350449519311387}},
doi = {\url{https://doi.org/10.1016/j.infrared.2020.103338}},
},
@InProceedings{Hou_2021_CVPR_CAB,
  author    = {Hou, Qibin and Zhou, Daquan and Feng, Jiashi},
  title     = {Coordinate Attention for Efficient Mobile Network Design},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2021},
  pages     = {13713-13722}
},
@ARTICLE{Zhao_2021_IEEE_SCGAN,
    author={Zhao, Yuzhi and Po, Lai-Man and Cheung, Kwok-Wai and Yu, Wing-Yin and Rehman, Yasar Abbas Ur},
    journal={IEEE Transactions on Circuits and Systems for Video Technology},
    title={SCGAN: Saliency Map-Guided Colorization With Generative Adversarial Network},
    year={2021},
    volume={31},
    number={8},
    pages={3062-3077},
    doi={\url{10.1109/TCSVT.2020.3037688}},
},
@INPROCEEDINGS{Berg_2018_CVPRW_TIR2Lab,
    author={Berg, Amanda and Ahlberg, Jorgen and Felsberg, Michael},
    booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
    title={Generating Visible Spectrum Images from Thermal Infrared},
    year={2018},
    volume={},
    number={},
    pages={1224-122409},
    doi={\url{10.1109/CVPRW.2018.00159}},
},
@Article{Luo_2022_IEEE_PearlGAN,
author = {Luo, Fuya and Li, Yunhan and Zeng, Guang and Peng, Peng and Wang, Gang and Li, Yongjie},
year = {2022},
month = {09},
pages = {1-16},
title = {Thermal Infrared Image Colorization for Nighttime Driving Scenes With Top-Down Guided Attention},
volume = {23},
journal = {IEEE Transactions on Intelligent Transportation Systems},
doi = {\url{10.1109/TITS.2022.3145476}},
},
@ARTICLE{Liao_2023_IEEE_MUGAN,
    author={Liao, Hangying and Jiang, Qian and Jin, Xin and Liu, Ling and Liu, Lin and Lee, Shin-Jye and Zhou, Wei},
    journal={IEEE Transactions on Intelligent Vehicles},
    title={MUGAN: Thermal Infrared Image Colorization Using Mixed-Skipping UNet and Generative Adversarial Network},
    year={2023},
    volume={8},
    number={4},
    pages={2954-2969},
    doi={\url{10.1109/TIV.2022.3218833}},
},
@Article{Zhou_2019_IEEE_UNetPlusPlus,
  title={UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation},
  author={Zongwei Zhou and Md Mahfuzur Rahman Siddiquee and Nima Tajbakhsh and Jianming Liang},
  journal={IEEE Transactions on Medical Imaging},
  year={2019},
  volume={39},
  pages={1856-1867},
  url={\url{https://api.semanticscholar.org/CorpusID:209202133}}
},
@Article{Huang_2020_ICASSP_UNet3+,
  title={UNet 3+: A Full-Scale Connected UNet for Medical Image Segmentation},
  author={Huimin Huang and Lanfen Lin and Ruofeng Tong and Hongjie Hu and Qiaowei Zhang and Yutaro Iwamoto and Xianhua Han and Yenwei Chen and Jian Wu},
  journal={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2020},
  pages={1055-1059},
  url={\url{https://api.semanticscholar.org/CorpusID:215828394}}
},
@InProceedings{Long_2015_CVPR_FCN,
author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
title = {Fully Convolutional Networks for Semantic Segmentation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
},
@InProceedings{Ronnenberger_2015_MICCAI_UNet,
    author={Ronneberger, Olaf
    and Fischer, Philipp
    and Brox, Thomas},
    title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
    booktitle="Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
    year="2015",
    pages="234--241",
    abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
    isbn="978-3-319-24574-4"
},
@InProceedings{Chen_2018_ECCV_DeepLabv3plus,
    author={Chen, Liang-Chieh
    and Zhu, Yukun
    and Papandreou, George
    and Schroff, Florian
    and Adam, Hartwig},
    title="Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation",
    booktitle="European Conference on Computer Vision (ECCV)",
    year="2018",
    pages="833--851",
    abstract="Spatial pyramid pooling module or encode-decoder structure are used in deep neural networks for semantic segmentation task. The former networks are able to encode multi-scale contextual information by probing the incoming features with filters or pooling operations at multiple rates and multiple effective fields-of-view, while the latter networks can capture sharper object boundaries by gradually recovering the spatial information. In this work, we propose to combine the advantages from both methods. Specifically, our proposed model, DeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module to refine the segmentation results especially along object boundaries. We further explore the Xception model and apply the depthwise separable convolution to both Atrous Spatial Pyramid Pooling and decoder modules, resulting in a faster and stronger encoder-decoder network. We demonstrate the effectiveness of the proposed model on PASCAL VOC 2012 and Cityscapes datasets, achieving the test set performance of 89{\%} and 82.1{\%} without any post-processing. Our paper is accompanied with a publicly available reference implementation of the proposed models in Tensorflow at https://github.com/tensorflow/models/tree/master/research/deeplab.",
    isbn="978-3-030-01234-2"
},
@InProceedings{Goodfellow_2014_NIPS_GAN,
 author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generative Adversarial Nets},
 volume = {27},
 year = {2014},
 url = {\url{https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf}}
},
@Article{He_2015_CVPR_Resnet,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
  journal={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778},
  url={\url{https://api.semanticscholar.org/CorpusID:206594692}}
},
@Article{Hou_2021_CVPR_CAB,
  title={Coordinate Attention for Efficient Mobile Network Design},
  author={Qibin Hou and Daquan Zhou and Jiashi Feng},
  journal={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021},
  pages={13708-13717},
  url={\url{https://api.semanticscholar.org/CorpusID:232110359}}
},
@Article{Aly_2005_IEEE_TotalVariation,
  title={Image up-sampling using total-variation regularization with a new observation model},
  author={Hussein H. Aly and Eric Dubois},
  journal={IEEE Transactions on Image Processing},
  year={2005},
  volume={14},
  pages={1647-1659},
  url={\url{https://api.semanticscholar.org/CorpusID:18582077}}
},
@InProceedings{Jhonson_2016_ECCV_PerceptualLosses,
    author={Johnson, Justin
    and Alahi, Alexandre
    and Fei-Fei, Li},
    title="Perceptual Losses for Real-Time Style Transfer and Super-Resolution",
    booktitle="European Conference on Computer Vision (ECCV)",
    year="2016",
    pages="694--711",
    abstract="We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by defining and optimizing perceptual loss functions based on high-level features extracted from pretrained networks. We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al.Â in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.",
    isbn="978-3-319-46475-6"
},
@Article{Li_2021_ACMMM_I2VGAN,
  title={I2V-GAN: Unpaired Infrared-to-Visible Video Translation},
  author={Shuang Li and Bingfeng Han and Zhengyang Yu and Chi Harold Liu and Kai Chen and Shuigen Wang},
  journal={Proceedings of the 29th ACM International Conference on Multimedia},
  year={2021},
  url={\url{https://api.semanticscholar.org/CorpusID:236772828}}
},
@Article{Hwang_2015_CVPR_KAIST,
  title={Multispectral pedestrian detection: Benchmark dataset and baseline},
  author={Soonmin Hwang and Jaesik Park and Namil Kim and Yukyung Choi and In-So Kweon},
  journal={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015},
  pages={1037-1045},
  url={\url{https://api.semanticscholar.org/CorpusID:8491618}}
},
@Article{Zhang_2020_ICIP_FLIR-Aligned,
  title={Multispectral Fusion for Object Detection with Cyclic Fuse-and-Refine Blocks},
  author={Heng Zhang and {\'E}lisa Fromont and S{\'e}bastien Lef{\`e}vre and Bruno Avignon},
  journal={IEEE International Conference on Image Processing (ICIP)},
  year={2020},
  pages={276-280},
  url={\url{https://api.semanticscholar.org/CorpusID:221970539}}
},
@Misc{FLIRDataset,
  author = {Teledyne FLIR LLC},
  title = {FLIR Thermal Dataset For Algorithm Training},
  howpublished = {\url{https://www.flir.com/oem/adas/adas-dataset-form/}},
  urldate = {2023-10-23}
},

@Misc{zoox_taxi,
    title = {FLIR to Provide Thermal Imaging Cameras for Zoox Robotaxi},
    howpublished = {\url{https://www.flir.com/news-center/camera-cores--components/flir-to-provide-thermal-imaging-cameras-for-zoox-robotaxi/}},
    urldate = {2023-11-15}
},
@Misc{FLIR_SAR,
    title = {Local Heroes: FLIR Airborne Cameras Assist U.S. Coast Guard in River Rescue},
    howpublished = {\url{https://www.flir.com/news-center/public-safety/local-heroes-flir-airborne-cameras-assist-u.s.-coast-guard-in-river-rescue/}},
    urldate = {2023-11-24},
},
@Article{Cordts_2016_CVPR_Cityscapes,
  title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
  author={Marius Cordts and Mohamed Omran and Sebastian Ramos and Timo Rehfeld and Markus Enzweiler and Rodrigo Benenson and Uwe Franke and Stefan Roth and Bernt Schiele},
  journal={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={3213-3223},
  url={\url{https://api.semanticscholar.org/CorpusID:502946}}
},
@InProceedings{Kingma_2015_ICLR_Adam,
  author    = {Kingma, Diederik and Ba, Jimmy},
  booktitle = {International Conference on Learning Representations (ICLR)},
  title     = {Adam: A Method for Stochastic Optimization},
  year      = {2015},
  optmonth  = {12}
},
@Article{Zhang_2018_CVPR_LPIPS,
  title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
  author={Richard Zhang and Phillip Isola and Alexei A. Efros and Eli Shechtman and Oliver Wang},
  journal={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018},
  pages={586-595},
  url={\url{https://api.semanticscholar.org/CorpusID:4766599}}
},
@InProceedings{Heusel_2017_NIPS_FID,
  title={GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
  author={Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter},
  booktitle={Neural Information Processing Systems},
  year={2017},
  url={\url{https://api.semanticscholar.org/CorpusID:326772}}
},
@Article{Badrinarayanan_2015_ArXiv_SegNet,
  title={SegNet: A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling},
  author={Vijay Badrinarayanan and Ankur Handa and Roberto Cipolla},
  journal={ArXiv},
  year={2015},
  volume={abs/1505.07293},
  url={\url{https://api.semanticscholar.org/CorpusID:11144038}}
},
@Article{Cheng_2015_ICCV_DeepC,
  title={Deep Colorization},
  author={Zezhou Cheng and Qingxiong Yang and Bin Sheng},
  journal={IEEE International Conference on Computer Vision (ICCV)},
  year={2015},
  pages={415-423},
  url={\url{https://api.semanticscholar.org/CorpusID:64884}}
},
@InProceedings{Zhao_2018_BMVC_PixellevelSG,
  title={Pixel-level Semantics Guided Image Colorization},
  author={Jiaojiao Zhao and Li Liu and Cees G. M. Snoek and J. Han and Ling Shao},
  booktitle={British Machine Vision Conference},
  year={2018},
  url={\url{https://api.semanticscholar.org/CorpusID:51926798}}
},
@Article{Mao_2016_CVPR_LSGAN,
  title={Least Squares Generative Adversarial Networks},
  author={Xudong Mao and Qing Li and Haoran Xie and Raymond Y. K. Lau and Zhen Wang and Stephen Paul Smolley},
  journal={IEEE International Conference on Computer Vision (ICCV)},
  year={2016},
  pages={2813-2821},
  url={\url{https://api.semanticscholar.org/CorpusID:206771128}}
},
@Article{Jolicoeur_2018_arXiv_RelativisticGAN,
  author       = {Alexia Jolicoeur{-}Martineau},
  title        = {The relativistic discriminator: a key element missing from standard
                  {GAN}},
  journal      = {CoRR},
  volume       = {abs/1807.00734},
  year         = {2018},
  eprinttype    = {arXiv},
  eprint       = {1807.00734},
  timestamp    = {Mon, 13 Aug 2018 16:46:29 +0200},
  url          = {\url{http://arxiv.org/abs/1807.00734}},
  biburl       = {\url{https://dblp.org/rec/journals/corr/abs-1807-00734.bib}},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
},
@InProceedings{Gulrajani_2017_NIPS_WGANGP,
  title={Improved Training of Wasserstein GANs},
  author={Ishaan Gulrajani and Faruk Ahmed and Mart{\'i}n Arjovsky and Vincent Dumoulin and Aaron C. Courville},
  booktitle={Neural Information Processing Systems},
  year={2017},
  url={\url{https://api.semanticscholar.org/CorpusID:10894094}}
},
@InProceedings{Simonyan_2015_ICLR_VGG,
  author       = "Karen Simonyan and Andrew Zisserman",
  title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
  booktitle    = "{International Conference on Learning Representations (ICLR)}",
  year         = "2015",
  pages        = {1-14}
},